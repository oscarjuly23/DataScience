# -*- coding: utf-8 -*-
"""IrisClassification_students_Oscar.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o2pDPqv7ef2PC0kqDaf9KuZ18H9s_27X

# Classification exercise

The dataset *iris* includes three iris species with 50 samples each as well as some properties about each flower. <br>

Classify the flowers according to their specie.
"""

# Load libraries
import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt

"""## Load data with pandas"""

#Create a data frame from the file separated by ","
iris = sns.load_dataset("iris")

"""## Data preparation"""

iris = sns.load_dataset("iris")

# print("Dataset size:", iris.shape)
# print("Missing values:\n", iris.isna().sum())  # We evaluate how many records have null values per variable
# print("Data Types:\n", iris.dtypes)  # Check the data types
# print("Distribution of the numeric features:\n", iris.describe())  #Some descriptive statistics of each attribute
# print("Distribution of the categorical feature:\n", iris["species"].value_counts()) # We start to analyze the data.

# Distribution of sepal_length (class attribute)
# sns.histplot(iris['sepal_length'])

#for c in iris.columns:
#  print(set(iris[c]))

iris_clean = iris.dropna()               # We remove null records with the .dropna() function
iris_clean2 = iris.dropna()               # We remove null records with the .dropna() function
# print("Number of registers without nulls: ", len(iris_clean)) # We ensure how many final samples we have

# Convert categorical attributes to dummy attributes
iris_clean['species'] = iris_clean['species'].astype('category')
iris_clean['species'] = iris_clean['species'].cat.codes
iris_clean['species'] = iris_clean['species'].astype('float64')
print("Data Types:\n", iris_clean.dtypes)
print()
print(iris_clean)

# SPECIES IS IMPORTANT? OR DELETE

# Correlation matrix
plt.figure(figsize = (10, 6))
sns.heatmap(iris_clean.corr(), annot = True)

sns.scatterplot(data=iris_clean2, x='sepal_length', y='sepal_width', hue='species')

sns.scatterplot(data=iris_clean2, x='petal_length', y='petal_width', hue='species')

# This set of scatterplots showing the relationship between all features in the iris dataset, grouped by species.
sns.pairplot(data=iris_clean2, hue="species")

"""## Classification
Create a model to classify species from the iris dataset, using the minimum number of attributes.

To classify species from the iris dataset using the minimum number of attributes, we can use the two most important features according to the correlation matrix and the scatterplot we analyzed previously. These features are petal length and petal width.
"""

from sklearn.model_selection import train_test_split

# PREPARING TRAIN & TEST:

# We divide the dataset in X (attributes) and y (class), and we split them on train and test sets

# Select only petal length and petal width as features
X = iris_clean[['petal_length', 'petal_width']]

# Set the species as the target variable
y = iris_clean['species']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)
target_names = y.unique()
feature_columns = X_train.columns

# CLASSIFICATION WITH LogisticRegression // RANDOM FOREST
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

model = LogisticRegression()  # Create a logistic regression model
model.fit(X_train, y_train) # Train the model using the training data

y_pred = model.predict(X_test)  # Use the trained model to make predictions on the test data

accuracy = accuracy_score(y_test, y_pred)
print("LogisticRegression Accuracy: ", accuracy)


#X1 = iris_clean[['petal_length', 'petal_width']]
#y1 = iris_clean['species']
#X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size = 0.25, random_state = 1)
#target_names = y.unique()
#feature_columns = X_train1.columns
#RF = RandomForestClassifier(n_estimators=100, random_state=42)  # Create Random Forest model with 100 trees
#RF.fit(X_train1, y_train1)
#y_pred_2 = RF.predict(X_test1)
#accuracy1 = accuracy_score(y_test1, y_pred_2)
#print("RanndomForest Accuracy:", accuracy1)